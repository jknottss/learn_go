
<!DOCTYPE html>
<html>
  <head>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-11222381-11"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-11222381-11');
    </script>

    <title>High performance servers without the event loop</title>
    <meta charset='utf-8'>
    <script>
      var notesEnabled =  true ;
    </script>
    <script src='/static/slides.js'></script>

    
    <script>
      var sections = [{"Number":[1],"Title":"whoami(1)","Elem":[{"Bullet":["Sysadmin before Devops","Transitioned to Go 5 years ago","Work for Canonical contributing to the Go project"]}],"Notes":null,"Classes":null,"Styles":null},{"Number":[2],"Title":"Who is this presentation for ?","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/pager.jpg","Width":400,"Height":0},{"Text":"The horror!"},{"Lines":["As an admin in a past life, the most stressful times in my career were defined by unsatisfying performance."],"Pre":false},{"Lines":["I got into Go because of its potential to build high performance servers."],"Pre":false},{"Lines":["As we're in a technical track, I'm not here to _tell_ you that Go is fast, instead I'm going to _explain_ why Go is fast."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[3],"Title":"An argument for an efficient programming language","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[4],"Title":"Moore's Law","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/CPU.png","Width":320,"Height":0},{"Text":"Image credit: [[http://www.gotw.ca/publications/concurrency-ddj.htm][Herb Sutter (Dr. Dobb's Journal, March 2005)]]"},{"Lines":["Moore's law states that the number of transistors per square inch doubles roughly every 18 months."],"Pre":false},{"Lines":["However, clock speeds topped out a decade ago with the Pentium 4 (Penryn) and have been slipping backwards since."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[5],"Title":"From space constrained to power constrained","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/sun-ultra-enterprise-450-400mhz-2gb-20-bay-workgroup-server-system-no-hdd-parts_131514071457.jpg","Width":0,"Height":0},{"Text":"Image credit: [[http://www.ccmostwanted.com/store/Sun-Ultra-Enterprise-450-400mhz-2gb-20-bay-Workgroup-Server-System-No-Hdd-Parts_131514071457.html][eBay]]"},{"Lines":["Sun Enterprise e450—about the size of a bar fridge, about the same power consumption."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[6],"Title":"Where does this power consumption come from ?","Elem":[{"URL":"https://rawgithub.com/davecheney/presentations/master/performance-without-the-event-loop/CMOS_Inverter.svg","Width":200,"Height":0},{"Text":"Source: [[https://en.wikipedia.org/wiki/CMOS][Wikipedia]]"},{"Lines":["CMOS stands for Complementary Metal Oxide Semiconductor, the _complementary_ part is the key."],"Pre":false},{"Lines":["When the circuit is on or off, no current flows directly from the source to the drain. However, during transitions there is a brief period where _both_ transistors are conducting."],"Pre":false},{"Lines":["Power consumption, and thus heat dissipation, is directly proportional to number of transition per second—Clock speed."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[7],"Title":"Right, thanks for the non sequitur","Elem":[{"Lines":["CPU feature size reductions are primarily aimed at reducing power consumption."],"Pre":false},{"Lines":["Reducing power consumption doesn't just mean \"green\". The primary goal is to keep power consumption, and thus heat dissipation, below levels that will damage the CPU."],"Pre":false},{"Lines":["Conversely, performance improvements come mainly from microarchitecture tweaks and esoteric vector instructions, which are not directly useful for the general computation."],"Pre":false},{"Lines":["Added up, each _microarchitecture_ (5 year cycle) change yields at most 10% improvement per generation, and most recently 4-6%."],"Pre":false},{"Lines":["Moore's Law is still in effect, but for the people in this room, the free lunch is over."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[8],"Title":"What's your point ?","Elem":[{"Lines":["So, why am I rambling on about hardware at a software conference ?"],"Pre":false},{"Lines":["The old adage that a slow language doesn't matter because hardware is getting faster, does not apply anymore."],"Pre":false},{"Lines":["If performance and scale is important to you, and arguably it is, as you're here in this session, then you'll agree with me that the days of throwing hardware at the problem are over - at least in the conventional sense."],"Pre":false},{"Lines":["You need a language which is efficient, because inefficient languages just do not justify themselves in production, at scale, on a capex basis."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[9],"Title":"An argument for a concurrent programming language","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[10],"Title":"CPUs are not getting faster, but they are getting wider","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/Ivy-Bridge_Die_Flat-HR.jpg","Width":700,"Height":0},{"Text":"Image Credit: Intel / [[http://www.anandtech.com/show/5875/dual-coregt2-ivy-bridge-die-measured-121mm2][AnandTech]]"},{"Lines":["So, CPUs are not getting faster, but they are getting wider."],"Pre":false},{"Bullet":["Hyper threading","More cores, dual core on mobile parts, quad core on desktop parts, even more cores on server parts."]}],"Notes":null,"Classes":null,"Styles":null},{"Number":[11],"Title":"Go on the server","Elem":[{"Lines":["A common refrain when talking about Go is it's a language that works well on the server; static binaries, powerful concurrency, and high performance."],"Pre":false},{"Lines":["This talk focuses on the last two items, how the language and the runtime transparently let Go programmers write highly scalable network servers, without having to worry about thread management or blocking I/O."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[12],"Title":"Processes, threads and Goroutines","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[13],"Title":"Your grandfather's server","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/3357832896_896d98bbaf_z.jpg","Width":0,"Height":0},{"Text":"Image Credit: [[https://www.flickr.com/photos/tascott/3357832896/in/album-72157615257588587/][Tom Scott]] (CC BY-NC-SA 2.0)"},{"Lines":["The first web server, [[http://info.cern.ch/Proposal.html][circa March 1989]]."],"Pre":false},{"Lines":["NCSA was the web server, which grew into Apache."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[14],"Title":"Processes","Elem":[{"Lines":["In the beginning computers ran one process at a time. Then in the 60’s the idea of multiprocessing, or time sharing became popular."],"Pre":false},{"Lines":["By the 70's this idea was well established for network servers, ftp(1), telnet(1), rlogin(1)."],"Pre":false},{"Lines":["This was the world of Berners-Lee's NCSA Mosaic server running on a 25Mhz Next Cube, every active HTTP session was handled by its own process."],"Pre":false},{"Lines":["In a time-sharing system the operating systems maintains the illusion of concurrency by rapidly switching the attention of the CPU between active processes by recording the state of the current process, then restoring the state of another."],"Pre":false},{"Lines":["This is called context switching."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[15],"Title":"Process context switching","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/640px-Table_of_x86_Registers_svg.svg.png","Width":0,"Height":0},{"Text":"Image credit: [[https://commons.wikimedia.org/wiki/File:Table_of_x86_Registers_svg.svg#/media/File:Table_of_x86_Registers_svg.svg][Immae (CC BY-SA 3.0)]]"},{"Lines":["There are three main costs of a context switch."],"Pre":false},{"Bullet":["The kernel needs to store the contents of all the CPU registers for that process, then restore the values for another process.","The kernel needs to flush the CPU’s virtual memory to physical mappings (TLB).","Overhead of the operating system context switch, and the overhead of the scheduler function to choose the next process to occupy the CPU."]}],"Notes":null,"Classes":null,"Styles":null},{"Number":[16],"Title":"Threads","Elem":[{"Lines":["This lead to the development of threads, which are conceptually the same as processes, but share the same memory space."],"Pre":false},{"Lines":["As threads share address space, they are lighter than processes, so they are faster to create and faster to switch between."],"Pre":false},{"Lines":["Threads still have an expensive context switch cost, a lot of state must be retained."],"Pre":false},{"Lines":["Goroutines take the idea of threads a step further."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[17],"Title":"Goroutines","Elem":[{"Lines":["Goroutines are cooperatively scheduled, rather than relying on the kernel to manage their time sharing."],"Pre":false},{"Lines":["The compiler knows the registers which are in use and saves them automatically."],"Pre":false},{"Lines":["The switch between goroutines only happens at well defined points, when an explicit call is made to the Go runtime scheduler."],"Pre":false},{"Bullet":["Channel send and receive operations, if those operations would block.","The Go statement, although there is no guarantee that new goroutine will be scheduled immediately.","Blocking syscalls like file and network operations.","After being stopped for a garbage collection cycle."]},{"Lines":["In other words, places where the goroutine cannot continue until it has more data, or more space to put data."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[18],"Title":"Goroutines","Elem":[{"Lines":["Many goroutines are multiplexed onto a single operating system thread."],"Pre":false},{"Bullet":["Super cheap to create.","Super cheap to switch between as it all happens in user space.","Tens of thousands of goroutines in a single process are the norm, hundreds of thousands not unexpected."]},{"Lines":["This results in relatively few operating system threads per Go process, with the Go runtime taking care of assigning a runnable Goroutine to a free operating system thread."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[19],"Title":"Goroutine example","Elem":[{"Text":"\n\n\n\u003cpre class=\"numbers\"\u003e\u003cspan num=\"11\"\u003efunc grep(r io.Reader, needle string) {\u003c/span\u003e\n\u003cspan num=\"12\"\u003e    br := bufio.NewReader(r)\u003c/span\u003e\n\u003cspan num=\"13\"\u003e    lines := make(chan string, 20)\u003c/span\u003e\n\u003cspan num=\"14\"\u003e\u003c/span\u003e\n\u003cspan num=\"15\"\u003e    go func() {\u003c/span\u003e\n\u003cspan num=\"16\"\u003e        defer close(lines)\u003c/span\u003e\n\u003cspan num=\"17\"\u003e        for {\u003c/span\u003e\n\u003cspan num=\"18\"\u003e            line, err := br.ReadString(\u0026#39;\\n\u0026#39;)\u003c/span\u003e\n\u003cspan num=\"19\"\u003e            if err != nil {\u003c/span\u003e\n\u003cspan num=\"20\"\u003e                return\u003c/span\u003e\n\u003cspan num=\"21\"\u003e            }\u003c/span\u003e\n\u003cspan num=\"22\"\u003e            lines \u0026lt;- line\u003c/span\u003e\n\u003cspan num=\"23\"\u003e        }\u003c/span\u003e\n\u003cspan num=\"24\"\u003e    }()\u003c/span\u003e\n\u003cspan num=\"25\"\u003e\u003c/span\u003e\n\u003cspan num=\"26\"\u003e    for line := range lines {\u003c/span\u003e\n\u003cspan num=\"27\"\u003e        if strings.Contains(line, needle) {\u003c/span\u003e\n\u003cspan num=\"28\"\u003e            fmt.Println(line)\u003c/span\u003e\n\u003cspan num=\"29\"\u003e        }\u003c/span\u003e\n\u003cspan num=\"30\"\u003e    }\u003c/span\u003e\n\u003cspan num=\"31\"\u003e}\u003c/span\u003e\n\u003c/pre\u003e\n\n\n","Play":false,"Edit":false,"FileName":"grep.go","Ext":".go","Raw":"ZnVuYyBncmVwKHIgaW8uUmVhZGVyLCBuZWVkbGUgc3RyaW5nKSB7CgliciA6PSBidWZpby5OZXdSZWFkZXIocikKCWxpbmVzIDo9IG1ha2UoY2hhbiBzdHJpbmcsIDIwKQoKCWdvIGZ1bmMoKSB7CgkJZGVmZXIgY2xvc2UobGluZXMpCgkJZm9yIHsKCQkJbGluZSwgZXJyIDo9IGJyLlJlYWRTdHJpbmcoJ1xuJykKCQkJaWYgZXJyICE9IG5pbCB7CgkJCQlyZXR1cm4KCQkJfQoJCQlsaW5lcyA8LSBsaW5lCgkJfQoJfSgpCgoJZm9yIGxpbmUgOj0gcmFuZ2UgbGluZXMgewoJCWlmIHN0cmluZ3MuQ29udGFpbnMobGluZSwgbmVlZGxlKSB7CgkJCWZtdC5QcmludGxuKGxpbmUpCgkJfQoJfQp9Cg=="}],"Notes":null,"Classes":null,"Styles":null},{"Number":[20],"Title":"Go uses a M:N scheduler in user space.","Elem":[{"Lines":["If you lived through green threads in Java or user space threads on Linux, then you may be feeling uncomfortable at this point. Let me assure you that in practice this user space scheduler works well. This is because it is integrated with the runtime."],"Pre":false},{"Lines":["A small number of operating system threads service runnable goroutines"],"Pre":false},{"Bullet":["Go versions 1.4 and lower, defaults to 1","Go versions 1.5 and above, defaults to the number of CPUs visible to the operating system."]},{"Lines":["Compare this to threaded applications, where a thread can be preempted at any time, at any instruction. In Go, the compiler handles this as a natural byproduct of the function call preamble."],"Pre":false},{"Lines":["From the point of view of the language, scheduling looks like a function call, and has the same function call semantics. The thread of execution calls into the scheduler with a specific goroutine stack, but may return with a different goroutine stack."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[21],"Title":"Stack management","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[22],"Title":"Process address space","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/process.png","Width":0,"Height":0},{"Lines":["This is a diagram of the memory layout of a process. The key thing we are interested is the location of the heap and the stack."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[23],"Title":"Stacks and guard pages","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/guard-page.png","Width":0,"Height":0},{"Lines":["Because the heap and stack overwriting each other would be catastrophic, the operating system arranges an area of unwritable memory between the stack and the heap."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[24],"Title":"Thread stacks","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/threads.png","Width":0,"Height":0},{"Lines":["Threads share the same address space, so for each thread, it must have its own stack, and its own guard page."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[25],"Title":"Goroutine stack management","Elem":[{"Lines":["The early process model, allowed the programmer to view the heap and the stack as effectively infinite. The downside was a complicated and expensive subprocess model."],"Pre":false},{"Lines":["Threads improved the situation a bit, but require the programmer to _guess_ the most appropriate stack size; too small, your program will abort, too large, you run out of virtual address space."],"Pre":false},{"Lines":["We’ve seen that the Go runtime schedules a large number of goroutines onto a small number of threads, but what about the stack requirements of those goroutines ?"],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[26],"Title":"Goroutine stack growth","Elem":[{"URL":"https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/stack-growth.png","Width":0,"Height":250},{"Lines":["Each goroutine starts with a small stack, allocated from the heap. The size has fluctuated over time, but in Go 1.5 each goroutine starts with a 2k allocation."],"Pre":false},{"Lines":["Instead of using guard pages, the Go compiler inserts a check as part of every function call to test if there is sufficient stack for the function to run."],"Pre":false},{"Lines":["If there is insufficient space, the runtime will allocate a large stack segment on the heap, copy the contents of the current stack to the new segment, free the old segment, and the function call restarted."],"Pre":false},{"Lines":["Because of this check, a goroutines initial stack can be made much smaller, which in turn permits Go programmers to treat goroutines as cheap resources."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[27],"Title":"Integrated network poller","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[28],"Title":"Dan Kegel's c10k problem","Elem":[{"Lines":["[[http://www.kegel.com/c10k.html]] circa 2002"],"Pre":false},{"Lines":["Question: How to hold up 10,000 concurrent TCP sessions on commodity hardware of the day."],"Pre":false},{"Lines":["Conventional wisdom suggested that high performance servers require native threads, or more recently, event loops."],"Pre":false},{"Lines":["Threads carry a high overhead in terms of scheduling cost and memory footprint."],"Pre":false},{"Lines":["Event loops ameliorate those costs, but introduce their own requirements for a complex callback driven style."],"Pre":false},{"Lines":["Go provides the best of both worlds."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[29],"Title":"Go's answer to c10k","Elem":[{"Lines":["In Go, syscalls are _usually_ blocking operations; `read(2)`, `write(2)`."],"Pre":false},{"Lines":["Scheduler would let the goroutines' backing thread block, then find or spawn another to continue to service other goroutines."],"Pre":false},{"Lines":["This works well for file IO as a small number of blocking threads can exhaust your local IO bandwidth."],"Pre":false},{"Lines":["For network sockets, almost all of your goroutines are going to be blocked waiting for network IO."],"Pre":false},{"Lines":["In a naive implementation this would mean as many threads as goroutines blocked waiting on network IO."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[30],"Title":"Socket Read / Write","Elem":[{"Text":"\n\n\n\u003cpre\u003e\u003cspan num=\"1\"\u003efunc (fd *netFD) Read(p []byte) (n int, err error) {\u003c/span\u003e\n\u003cspan num=\"2\"\u003e    // preamble\u003c/span\u003e\n\u003cspan num=\"3\"\u003e    for {\u003c/span\u003e\n\u003cspan num=\"4\"\u003e        \u003cb\u003en, err = syscall.Read(fd.sysfd, p)\u003c/b\u003e\u003c/span\u003e\n\u003cspan num=\"5\"\u003e        if err != nil {\u003c/span\u003e\n\u003cspan num=\"6\"\u003e            n = 0\u003c/span\u003e\n\u003cspan num=\"7\"\u003e            if err == syscall.EAGAIN {\u003c/span\u003e\n\u003cspan num=\"8\"\u003e                \u003cb\u003eif err = fd.pd.WaitRead(); err == nil {\u003c/b\u003e\u003c/span\u003e\n\u003cspan num=\"9\"\u003e                    continue\u003c/span\u003e\n\u003cspan num=\"10\"\u003e                }\u003c/span\u003e\n\u003cspan num=\"11\"\u003e            }\u003c/span\u003e\n\u003cspan num=\"12\"\u003e        }\u003c/span\u003e\n\u003cspan num=\"13\"\u003e        err = fd.eofError(n, err)\u003c/span\u003e\n\u003cspan num=\"14\"\u003e        break\u003c/span\u003e\n\u003cspan num=\"15\"\u003e    }\u003c/span\u003e\n\u003cspan num=\"16\"\u003e    // epilog\u003c/span\u003e\n\u003cspan num=\"17\"\u003e    return\u003c/span\u003e\n\u003cspan num=\"18\"\u003e}\u003c/span\u003e\n\u003c/pre\u003e\n\n\n","Play":false,"Edit":false,"FileName":"read.go","Ext":".go","Raw":"ZnVuYyAoZmQgKm5ldEZEKSBSZWFkKHAgW11ieXRlKSAobiBpbnQsIGVyciBlcnJvcikgewoJLy8gcHJlYW1ibGUKCWZvciB7CgkJbiwgZXJyID0gc3lzY2FsbC5SZWFkKGZkLnN5c2ZkLCBwKSAvLyBITAoJCWlmIGVyciAhPSBuaWwgewoJCQluID0gMAoJCQlpZiBlcnIgPT0gc3lzY2FsbC5FQUdBSU4gewoJCQkJaWYgZXJyID0gZmQucGQuV2FpdFJlYWQoKTsgZXJyID09IG5pbCB7IC8vIEhMCgkJCQkJY29udGludWUKCQkJCX0KCQkJfQoJCX0KCQllcnIgPSBmZC5lb2ZFcnJvcihuLCBlcnIpCgkJYnJlYWsKCX0KCS8vIGVwaWxvZwoJcmV0dXJuCn0K"}],"Notes":null,"Classes":null,"Styles":null},{"Number":[31],"Title":"Integrated poller","Elem":[{"Lines":["In older versions of Go, this was handled by a single goroutine which used select(2) / kqueue(2) / epoll(2), IOCP (windows)."],"Pre":false},{"Lines":["In current versions of Go this has been integrated into the runtime."],"Pre":false},{"Lines":["The runtime knows which goroutine is waiting for the socket to become ready and can put it back on the same CPU."],"Pre":false},{"Lines":["Async file IO is a slightly harder problem due to spotty operating system support. Maybe for Go 1.6."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[32],"Title":"Conclusion","Elem":null,"Notes":null,"Classes":null,"Styles":null},{"Number":[33],"Title":"Goroutines, stack management, and an integrated network poller","Elem":[{"Lines":["Goroutines provide a powerful abstraction that frees the programmer from worrying about thread pools or event loops."],"Pre":false},{"Lines":["The stack of a goroutine is as big as it needs to be without being concerned about sizing thread stacks or thread pools."],"Pre":false},{"Lines":["The integrated network poller lets Go programmers avoid convoluted callback styles while still leveraging the most efficient IO completion logic available with the operating system."],"Pre":false},{"Lines":["The runtime makes sure that there will be just enough threads to service all your goroutines and keep your cores active."],"Pre":false},{"Lines":["All of these features are transparent to the programmer."],"Pre":false}],"Notes":null,"Classes":null,"Styles":null},{"Number":[34],"Title":"But wait, there's more","Elem":[{"Lines":["As this is the performance track, I've mostly constrained my remarks to this area, but there is a lot more to the Go success story than just being fast, and these are arguably the more notable features of the language."],"Pre":false},{"Bullet":["Super fast compilation.","Excellent tooling; go build, go test, go fmt, go lint, go vet, godoc, -race detector.","Excellent cross platform support, cross compilation without tears","Single static binary enables a ridiculously simple deployment story, `scp(1)` and you're done -- no runtime interpreter required."]}],"Notes":null,"Classes":null,"Styles":null},{"Number":[35],"Title":"Success stories","Elem":[{"Bullet":["Vitess (mysql proxy that sits between every db call behind Youtube)","dl.google.com","New York Times","Hailo","Facebook/Parse","Docker","CoreOS; fleet, etcd, rkt","Kubernetes","Baidu","Qihoo 360","[[https://github.com/golang/go/wiki/GoUsers][... and many more]]"]}],"Notes":null,"Classes":null,"Styles":null},{"Number":[36],"Title":"Would you like to know more ?","Elem":[{"Lines":["Go take the tour"],"Pre":false},{"Lines":["[[https://tour.golang.org]]"],"Pre":false},{"Lines":["Go join a meetup"],"Pre":false},{"Lines":["[[https://go-meetups.appspot.com]]"],"Pre":false},{"Lines":["Go watch some more talks"],"Pre":false},{"Lines":["[[http://gophervids.appspot.com]]"],"Pre":false}],"Notes":null,"Classes":null,"Styles":null}];
      var titleNotes =  null 
    </script>
    <script src='/static/notes.js'></script>
    
  </head>

  <body style='display: none'>

    <section class='slides layout-widescreen'>

      <article>
        <h1>High performance servers without the event loop</h1>
        <h3>OSCON, Portland</h3>
        <h3>21 July 2015</h3>
        
          <div class="presenter">
            
  
  <p>
    Dave Cheney
  </p>
  

          </div>
        
      </article>

  
  
      <article >
      
        <h3>whoami(1)</h3>
        
  <ul>
  
    <li>Sysadmin before Devops</li>
  
    <li>Transitioned to Go 5 years ago</li>
  
    <li>Work for Canonical contributing to the Go project</li>
  
  </ul>

      
      <span class="pagenumber">2</span>
      </article>
  
  
  
      <article >
      
        <h3>Who is this presentation for ?</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/pager.jpg" width="400">
</div>
<figcaption>The horror!</figcaption>
  
  <p>
    As an admin in a past life, the most stressful times in my career were defined by unsatisfying performance.
  </p>
  

  
  <p>
    I got into Go because of its potential to build high performance servers.
  </p>
  

  
  <p>
    As we&#39;re in a technical track, I&#39;m not here to <i>tell</i> you that Go is fast, instead I&#39;m going to <i>explain</i> why Go is fast.
  </p>
  

      
      <span class="pagenumber">3</span>
      </article>
  
  
  
      <article >
      
        <h2>An argument for an efficient programming language</h2>
      
      <span class="pagenumber">4</span>
      </article>
  
  
  
      <article >
      
        <h3>Moore&#39;s Law</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/CPU.png" width="320">
</div>
<figcaption>Image credit: <a href="http://www.gotw.ca/publications/concurrency-ddj.htm" target="_blank">Herb Sutter (Dr. Dobb&#39;s Journal, March 2005)</a></figcaption>
  
  <p>
    Moore&#39;s law states that the number of transistors per square inch doubles roughly every 18 months.
  </p>
  

  
  <p>
    However, clock speeds topped out a decade ago with the Pentium 4 (Penryn) and have been slipping backwards since.
  </p>
  

      
      <span class="pagenumber">5</span>
      </article>
  
  
  
      <article >
      
        <h3>From space constrained to power constrained</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/sun-ultra-enterprise-450-400mhz-2gb-20-bay-workgroup-server-system-no-hdd-parts_131514071457.jpg">
</div>
<figcaption>Image credit: <a href="http://www.ccmostwanted.com/store/Sun-Ultra-Enterprise-450-400mhz-2gb-20-bay-Workgroup-Server-System-No-Hdd-Parts_131514071457.html" target="_blank">eBay</a></figcaption>
  
  <p>
    Sun Enterprise e450—about the size of a bar fridge, about the same power consumption.
  </p>
  

      
      <span class="pagenumber">6</span>
      </article>
  
  
  
      <article >
      
        <h3>Where does this power consumption come from ?</h3>
        
<div class="image">
  <img src="https://rawgithub.com/davecheney/presentations/master/performance-without-the-event-loop/CMOS_Inverter.svg" width="200">
</div>
<figcaption>Source: <a href="https://en.wikipedia.org/wiki/CMOS" target="_blank">Wikipedia</a></figcaption>
  
  <p>
    CMOS stands for Complementary Metal Oxide Semiconductor, the <i>complementary</i> part is the key.
  </p>
  

  
  <p>
    When the circuit is on or off, no current flows directly from the source to the drain. However, during transitions there is a brief period where <i>both</i> transistors are conducting.
  </p>
  

  
  <p>
    Power consumption, and thus heat dissipation, is directly proportional to number of transition per second—Clock speed.
  </p>
  

      
      <span class="pagenumber">7</span>
      </article>
  
  
  
      <article >
      
        <h3>Right, thanks for the non sequitur</h3>
        
  
  <p>
    CPU feature size reductions are primarily aimed at reducing power consumption.
  </p>
  

  
  <p>
    Reducing power consumption doesn&#39;t just mean &#34;green&#34;. The primary goal is to keep power consumption, and thus heat dissipation, below levels that will damage the CPU.
  </p>
  

  
  <p>
    Conversely, performance improvements come mainly from microarchitecture tweaks and esoteric vector instructions, which are not directly useful for the general computation.
  </p>
  

  
  <p>
    Added up, each <i>microarchitecture</i> (5 year cycle) change yields at most 10% improvement per generation, and most recently 4-6%.
  </p>
  

  
  <p>
    Moore&#39;s Law is still in effect, but for the people in this room, the free lunch is over.
  </p>
  

      
      <span class="pagenumber">8</span>
      </article>
  
  
  
      <article >
      
        <h3>What&#39;s your point ?</h3>
        
  
  <p>
    So, why am I rambling on about hardware at a software conference ?
  </p>
  

  
  <p>
    The old adage that a slow language doesn&#39;t matter because hardware is getting faster, does not apply anymore.
  </p>
  

  
  <p>
    If performance and scale is important to you, and arguably it is, as you&#39;re here in this session, then you&#39;ll agree with me that the days of throwing hardware at the problem are over - at least in the conventional sense.
  </p>
  

  
  <p>
    You need a language which is efficient, because inefficient languages just do not justify themselves in production, at scale, on a capex basis.
  </p>
  

      
      <span class="pagenumber">9</span>
      </article>
  
  
  
      <article >
      
        <h2>An argument for a concurrent programming language</h2>
      
      <span class="pagenumber">10</span>
      </article>
  
  
  
      <article >
      
        <h3>CPUs are not getting faster, but they are getting wider</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/Ivy-Bridge_Die_Flat-HR.jpg" width="700">
</div>
<figcaption>Image Credit: Intel / <a href="http://www.anandtech.com/show/5875/dual-coregt2-ivy-bridge-die-measured-121mm2" target="_blank">AnandTech</a></figcaption>
  
  <p>
    So, CPUs are not getting faster, but they are getting wider.
  </p>
  

  <ul>
  
    <li>Hyper threading</li>
  
    <li>More cores, dual core on mobile parts, quad core on desktop parts, even more cores on server parts.</li>
  
  </ul>

      
      <span class="pagenumber">11</span>
      </article>
  
  
  
      <article >
      
        <h3>Go on the server</h3>
        
  
  <p>
    A common refrain when talking about Go is it&#39;s a language that works well on the server; static binaries, powerful concurrency, and high performance.
  </p>
  

  
  <p>
    This talk focuses on the last two items, how the language and the runtime transparently let Go programmers write highly scalable network servers, without having to worry about thread management or blocking I/O.
  </p>
  

      
      <span class="pagenumber">12</span>
      </article>
  
  
  
      <article >
      
        <h2>Processes, threads and Goroutines</h2>
      
      <span class="pagenumber">13</span>
      </article>
  
  
  
      <article >
      
        <h3>Your grandfather&#39;s server</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/3357832896_896d98bbaf_z.jpg">
</div>
<figcaption>Image Credit: <a href="https://www.flickr.com/photos/tascott/3357832896/in/album-72157615257588587/" target="_blank">Tom Scott</a> (CC BY-NC-SA 2.0)</figcaption>
  
  <p>
    The first web server, <a href="http://info.cern.ch/Proposal.html" target="_blank">circa March 1989</a>.
  </p>
  

  
  <p>
    NCSA was the web server, which grew into Apache.
  </p>
  

      
      <span class="pagenumber">14</span>
      </article>
  
  
  
      <article >
      
        <h3>Processes</h3>
        
  
  <p>
    In the beginning computers ran one process at a time. Then in the 60’s the idea of multiprocessing, or time sharing became popular.
  </p>
  

  
  <p>
    By the 70&#39;s this idea was well established for network servers, ftp(1), telnet(1), rlogin(1).
  </p>
  

  
  <p>
    This was the world of Berners-Lee&#39;s NCSA Mosaic server running on a 25Mhz Next Cube, every active HTTP session was handled by its own process.
  </p>
  

  
  <p>
    In a time-sharing system the operating systems maintains the illusion of concurrency by rapidly switching the attention of the CPU between active processes by recording the state of the current process, then restoring the state of another.
  </p>
  

  
  <p>
    This is called context switching.
  </p>
  

      
      <span class="pagenumber">15</span>
      </article>
  
  
  
      <article >
      
        <h3>Process context switching</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/640px-Table_of_x86_Registers_svg.svg.png">
</div>
<figcaption>Image credit: <a href="https://commons.wikimedia.org/wiki/File:Table_of_x86_Registers_svg.svg#/media/File:Table_of_x86_Registers_svg.svg" target="_blank">Immae (CC BY-SA 3.0)</a></figcaption>
  
  <p>
    There are three main costs of a context switch.
  </p>
  

  <ul>
  
    <li>The kernel needs to store the contents of all the CPU registers for that process, then restore the values for another process.</li>
  
    <li>The kernel needs to flush the CPU’s virtual memory to physical mappings (TLB).</li>
  
    <li>Overhead of the operating system context switch, and the overhead of the scheduler function to choose the next process to occupy the CPU.</li>
  
  </ul>

      
      <span class="pagenumber">16</span>
      </article>
  
  
  
      <article >
      
        <h3>Threads</h3>
        
  
  <p>
    This lead to the development of threads, which are conceptually the same as processes, but share the same memory space.
  </p>
  

  
  <p>
    As threads share address space, they are lighter than processes, so they are faster to create and faster to switch between.
  </p>
  

  
  <p>
    Threads still have an expensive context switch cost, a lot of state must be retained.
  </p>
  

  
  <p>
    Goroutines take the idea of threads a step further.
  </p>
  

      
      <span class="pagenumber">17</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutines</h3>
        
  
  <p>
    Goroutines are cooperatively scheduled, rather than relying on the kernel to manage their time sharing.
  </p>
  

  
  <p>
    The compiler knows the registers which are in use and saves them automatically.
  </p>
  

  
  <p>
    The switch between goroutines only happens at well defined points, when an explicit call is made to the Go runtime scheduler.
  </p>
  

  <ul>
  
    <li>Channel send and receive operations, if those operations would block.</li>
  
    <li>The Go statement, although there is no guarantee that new goroutine will be scheduled immediately.</li>
  
    <li>Blocking syscalls like file and network operations.</li>
  
    <li>After being stopped for a garbage collection cycle.</li>
  
  </ul>

  
  <p>
    In other words, places where the goroutine cannot continue until it has more data, or more space to put data.
  </p>
  

      
      <span class="pagenumber">18</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutines</h3>
        
  
  <p>
    Many goroutines are multiplexed onto a single operating system thread.
  </p>
  

  <ul>
  
    <li>Super cheap to create.</li>
  
    <li>Super cheap to switch between as it all happens in user space.</li>
  
    <li>Tens of thousands of goroutines in a single process are the norm, hundreds of thousands not unexpected.</li>
  
  </ul>

  
  <p>
    This results in relatively few operating system threads per Go process, with the Go runtime taking care of assigning a runnable Goroutine to a free operating system thread.
  </p>
  

      
      <span class="pagenumber">19</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutine example</h3>
        
  <div class="code" >


<pre class="numbers"><span num="11">func grep(r io.Reader, needle string) {</span>
<span num="12">    br := bufio.NewReader(r)</span>
<span num="13">    lines := make(chan string, 20)</span>
<span num="14"></span>
<span num="15">    go func() {</span>
<span num="16">        defer close(lines)</span>
<span num="17">        for {</span>
<span num="18">            line, err := br.ReadString(&#39;\n&#39;)</span>
<span num="19">            if err != nil {</span>
<span num="20">                return</span>
<span num="21">            }</span>
<span num="22">            lines &lt;- line</span>
<span num="23">        }</span>
<span num="24">    }()</span>
<span num="25"></span>
<span num="26">    for line := range lines {</span>
<span num="27">        if strings.Contains(line, needle) {</span>
<span num="28">            fmt.Println(line)</span>
<span num="29">        }</span>
<span num="30">    }</span>
<span num="31">}</span>
</pre>


</div>

      
      <span class="pagenumber">20</span>
      </article>
  
  
  
      <article >
      
        <h3>Go uses a M:N scheduler in user space.</h3>
        
  
  <p>
    If you lived through green threads in Java or user space threads on Linux, then you may be feeling uncomfortable at this point. Let me assure you that in practice this user space scheduler works well. This is because it is integrated with the runtime.
  </p>
  

  
  <p>
    A small number of operating system threads service runnable goroutines
  </p>
  

  <ul>
  
    <li>Go versions 1.4 and lower, defaults to 1</li>
  
    <li>Go versions 1.5 and above, defaults to the number of CPUs visible to the operating system.</li>
  
  </ul>

  
  <p>
    Compare this to threaded applications, where a thread can be preempted at any time, at any instruction. In Go, the compiler handles this as a natural byproduct of the function call preamble.
  </p>
  

  
  <p>
    From the point of view of the language, scheduling looks like a function call, and has the same function call semantics. The thread of execution calls into the scheduler with a specific goroutine stack, but may return with a different goroutine stack.
  </p>
  

      
      <span class="pagenumber">21</span>
      </article>
  
  
  
      <article >
      
        <h2>Stack management</h2>
      
      <span class="pagenumber">22</span>
      </article>
  
  
  
      <article >
      
        <h3>Process address space</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/process.png">
</div>

  
  <p>
    This is a diagram of the memory layout of a process. The key thing we are interested is the location of the heap and the stack.
  </p>
  

      
      <span class="pagenumber">23</span>
      </article>
  
  
  
      <article >
      
        <h3>Stacks and guard pages</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/guard-page.png">
</div>

  
  <p>
    Because the heap and stack overwriting each other would be catastrophic, the operating system arranges an area of unwritable memory between the stack and the heap.
  </p>
  

      
      <span class="pagenumber">24</span>
      </article>
  
  
  
      <article >
      
        <h3>Thread stacks</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/threads.png">
</div>

  
  <p>
    Threads share the same address space, so for each thread, it must have its own stack, and its own guard page.
  </p>
  

      
      <span class="pagenumber">25</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutine stack management</h3>
        
  
  <p>
    The early process model, allowed the programmer to view the heap and the stack as effectively infinite. The downside was a complicated and expensive subprocess model.
  </p>
  

  
  <p>
    Threads improved the situation a bit, but require the programmer to <i>guess</i> the most appropriate stack size; too small, your program will abort, too large, you run out of virtual address space.
  </p>
  

  
  <p>
    We’ve seen that the Go runtime schedules a large number of goroutines onto a small number of threads, but what about the stack requirements of those goroutines ?
  </p>
  

      
      <span class="pagenumber">26</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutine stack growth</h3>
        
<div class="image">
  <img src="https://raw.githubusercontent.com/davecheney/presentations/master/performance-without-the-event-loop/stack-growth.png" height="250">
</div>

  
  <p>
    Each goroutine starts with a small stack, allocated from the heap. The size has fluctuated over time, but in Go 1.5 each goroutine starts with a 2k allocation.
  </p>
  

  
  <p>
    Instead of using guard pages, the Go compiler inserts a check as part of every function call to test if there is sufficient stack for the function to run.
  </p>
  

  
  <p>
    If there is insufficient space, the runtime will allocate a large stack segment on the heap, copy the contents of the current stack to the new segment, free the old segment, and the function call restarted.
  </p>
  

  
  <p>
    Because of this check, a goroutines initial stack can be made much smaller, which in turn permits Go programmers to treat goroutines as cheap resources.
  </p>
  

      
      <span class="pagenumber">27</span>
      </article>
  
  
  
      <article >
      
        <h2>Integrated network poller</h2>
      
      <span class="pagenumber">28</span>
      </article>
  
  
  
      <article >
      
        <h3>Dan Kegel&#39;s c10k problem</h3>
        
  
  <p>
    <a href="http://www.kegel.com/c10k.html" target="_blank">www.kegel.com/c10k.html</a> circa 2002
  </p>
  

  
  <p>
    Question: How to hold up 10,000 concurrent TCP sessions on commodity hardware of the day.
  </p>
  

  
  <p>
    Conventional wisdom suggested that high performance servers require native threads, or more recently, event loops.
  </p>
  

  
  <p>
    Threads carry a high overhead in terms of scheduling cost and memory footprint.
  </p>
  

  
  <p>
    Event loops ameliorate those costs, but introduce their own requirements for a complex callback driven style.
  </p>
  

  
  <p>
    Go provides the best of both worlds.
  </p>
  

      
      <span class="pagenumber">29</span>
      </article>
  
  
  
      <article >
      
        <h3>Go&#39;s answer to c10k</h3>
        
  
  <p>
    In Go, syscalls are <i>usually</i> blocking operations; <code>read(2)</code>, <code>write(2)</code>.
  </p>
  

  
  <p>
    Scheduler would let the goroutines&#39; backing thread block, then find or spawn another to continue to service other goroutines.
  </p>
  

  
  <p>
    This works well for file IO as a small number of blocking threads can exhaust your local IO bandwidth.
  </p>
  

  
  <p>
    For network sockets, almost all of your goroutines are going to be blocked waiting for network IO.
  </p>
  

  
  <p>
    In a naive implementation this would mean as many threads as goroutines blocked waiting on network IO.
  </p>
  

      
      <span class="pagenumber">30</span>
      </article>
  
  
  
      <article >
      
        <h3>Socket Read / Write</h3>
        
  <div class="code" >


<pre><span num="1">func (fd *netFD) Read(p []byte) (n int, err error) {</span>
<span num="2">    // preamble</span>
<span num="3">    for {</span>
<span num="4">        <b>n, err = syscall.Read(fd.sysfd, p)</b></span>
<span num="5">        if err != nil {</span>
<span num="6">            n = 0</span>
<span num="7">            if err == syscall.EAGAIN {</span>
<span num="8">                <b>if err = fd.pd.WaitRead(); err == nil {</b></span>
<span num="9">                    continue</span>
<span num="10">                }</span>
<span num="11">            }</span>
<span num="12">        }</span>
<span num="13">        err = fd.eofError(n, err)</span>
<span num="14">        break</span>
<span num="15">    }</span>
<span num="16">    // epilog</span>
<span num="17">    return</span>
<span num="18">}</span>
</pre>


</div>

      
      <span class="pagenumber">31</span>
      </article>
  
  
  
      <article >
      
        <h3>Integrated poller</h3>
        
  
  <p>
    In older versions of Go, this was handled by a single goroutine which used select(2) / kqueue(2) / epoll(2), IOCP (windows).
  </p>
  

  
  <p>
    In current versions of Go this has been integrated into the runtime.
  </p>
  

  
  <p>
    The runtime knows which goroutine is waiting for the socket to become ready and can put it back on the same CPU.
  </p>
  

  
  <p>
    Async file IO is a slightly harder problem due to spotty operating system support. Maybe for Go 1.6.
  </p>
  

      
      <span class="pagenumber">32</span>
      </article>
  
  
  
      <article >
      
        <h2>Conclusion</h2>
      
      <span class="pagenumber">33</span>
      </article>
  
  
  
      <article >
      
        <h3>Goroutines, stack management, and an integrated network poller</h3>
        
  
  <p>
    Goroutines provide a powerful abstraction that frees the programmer from worrying about thread pools or event loops.
  </p>
  

  
  <p>
    The stack of a goroutine is as big as it needs to be without being concerned about sizing thread stacks or thread pools.
  </p>
  

  
  <p>
    The integrated network poller lets Go programmers avoid convoluted callback styles while still leveraging the most efficient IO completion logic available with the operating system.
  </p>
  

  
  <p>
    The runtime makes sure that there will be just enough threads to service all your goroutines and keep your cores active.
  </p>
  

  
  <p>
    All of these features are transparent to the programmer.
  </p>
  

      
      <span class="pagenumber">34</span>
      </article>
  
  
  
      <article >
      
        <h3>But wait, there&#39;s more</h3>
        
  
  <p>
    As this is the performance track, I&#39;ve mostly constrained my remarks to this area, but there is a lot more to the Go success story than just being fast, and these are arguably the more notable features of the language.
  </p>
  

  <ul>
  
    <li>Super fast compilation.</li>
  
    <li>Excellent tooling; go build, go test, go fmt, go lint, go vet, godoc, -race detector.</li>
  
    <li>Excellent cross platform support, cross compilation without tears</li>
  
    <li>Single static binary enables a ridiculously simple deployment story, <code>scp(1)</code> and you&#39;re done -- no runtime interpreter required.</li>
  
  </ul>

      
      <span class="pagenumber">35</span>
      </article>
  
  
  
      <article >
      
        <h3>Success stories</h3>
        
  <ul>
  
    <li>Vitess (mysql proxy that sits between every db call behind Youtube)</li>
  
    <li>dl.google.com</li>
  
    <li>New York Times</li>
  
    <li>Hailo</li>
  
    <li>Facebook/Parse</li>
  
    <li>Docker</li>
  
    <li>CoreOS; fleet, etcd, rkt</li>
  
    <li>Kubernetes</li>
  
    <li>Baidu</li>
  
    <li>Qihoo 360</li>
  
    <li><a href="https://github.com/golang/go/wiki/GoUsers" target="_blank">... and many more</a></li>
  
  </ul>

      
      <span class="pagenumber">36</span>
      </article>
  
  
  
      <article >
      
        <h3>Would you like to know more ?</h3>
        
  
  <p>
    Go take the tour
  </p>
  

  
  <p>
    <a href="https://tour.golang.org" target="_blank">tour.golang.org</a>
  </p>
  

  
  <p>
    Go join a meetup
  </p>
  

  
  <p>
    <a href="https://go-meetups.appspot.com" target="_blank">go-meetups.appspot.com</a>
  </p>
  

  
  <p>
    Go watch some more talks
  </p>
  

  
  <p>
    <a href="http://gophervids.appspot.com" target="_blank">gophervids.appspot.com</a>
  </p>
  

      
      <span class="pagenumber">37</span>
      </article>
  
  

      <article>
        <h3>Thank you</h3>
        
          <div class="presenter">
            
  
  <p>
    Dave Cheney
  </p>
  
<p class="link"><a href="mailto:dave@cheney.net" target="_blank">dave@cheney.net</a></p><p class="link"><a href="http://dave.cheney.net/" target="_blank">http://dave.cheney.net/</a></p><p class="link"><a href="http://twitter.com/davecheney" target="_blank">@davecheney</a></p>
          </div>
        
      </article>

    </section>

    <div id="help">
      Use the left and right arrow keys or click the left and right
      edges of the page to navigate between slides.<br>
      (Press 'H' or navigate to hide this message.)
    </div>

    
    <script src='/play.js'></script>
    
  </body>
</html>
