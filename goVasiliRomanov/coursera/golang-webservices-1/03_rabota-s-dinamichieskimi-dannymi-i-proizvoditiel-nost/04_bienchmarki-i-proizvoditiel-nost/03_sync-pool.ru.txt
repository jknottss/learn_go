[БЕЗ_ЗВУКА] В примерах с распаковкой
бинарных данных мы видели, что пример с рефлексией, он медленней,
в нем больше аллокаций памяти, и он в целом требует больше
памяти на одну операцию. Это видно на экране. Рефлексия и кодогенерация. Возникает это потому,
что рантайму go нужно выделить память в данном случае каждый
раз на каждую операцию. Выделение памяти — на самом
деле это достаточно дорогая операция по сравнению со всем остальным. И иногда хочется не выделять
новую память каждый раз, а переиспользовать какой-то пул памяти, чтобы там уже были
приаллоцированные объекты. Это будет быстрее. В go есть инструмент для этого,
называется он sync.Pool. Посмотрим код. Итак, sync.Pool находится в пакете sync. Вот у нас есть тест,
у нас есть какая-то структура, где довольно много полей, то есть она
занимает достаточно много места в памяти. Есть какая-то тестовая структура
уже с заполненными данными, экземпляр этой структуры. Вот.
И какой-то список, да? Чтобы еще данных было еще побольше. Теперь рассмотрим первый тест, когда мы будем каждый раз
аллоцировать новые данные. Мы будем сериализовать этот набор структур, Pages, просто в json. В случае, если мы будем каждый
раз его аллоцировать с нуля, то мы будем каждый раз выделять
слайс байт на 64 байта вот здесь, создавать буфер, куда мы будем писать. После этого мы создадим json Encoder,
который умеет писать в тот буфер, который мы ему передадим,
ну и он делает Encode. То есть каждая операция,
каждая операция... Причем мы запускаем тест параллельно, то есть несколько тестов
будут идти одновременно. На каждую операцию, на каждый запуск этого
теста будет выделение памяти, каждый раз. Теперь рассмотрим вариант с пулом. Мы объявили переменную dataPool. dataPool — это в общем
экземпляр структуры sync.Pool, в нем есть только одна функция — New. Она возвращает нам новый объект,
если вдруг его не было уже в пуле. Ну, нам же нужно когда-то
инициализировать его. Мы должны всегда возврващать interface. Ну, потому что все-таки это
универсальный инструмент. Итак, мы просто возвращаем bytes. Фактически это то же самое, что мы делаем
при аллокации в рассмотренном тесте. Я это выделил, можно видеть. Это одна и та же строка. Вот.
Теперь тест, который не аллоцирует данные заново,
а берет их из пула. Итак, фактически это тот же самый код, в котором добавились несколько строк: раз,
два и три. Первая строка,
мы в ней раньше аллоцировали данные, а теперь мы обращаемся к пулу,
получаем элемент, и этот элемент сразу же преобразуем
к нужному нам типу, потому что там возвращается пустой interface,
просто так мы использовать его не можем. Хорошо. Получили Pool. Эта строка осталась без изменений,
мы по-прежнему сериализуем в него. Теперь идет отличие. Мы сбрасываем эти данные: мы их нигде
не использовали, мы их поэтому... тот слайс байт,
мы просто его сбрасываем: data.Reset. И возвращаем данные в
пул обратно: Put(data). Какой вариант быстрее? Ну давайте запускать. Так. Запускаем сразу с тестированием
памяти и смотрим. Вариант с аллокациями и вариант с пулом. Обратите внимание: вариант с аллокациями,
с новыми аллокациями, делает пять аллокаций на операцию. Вариант с пулом делает всего
две аллокации на операцию. При этом вариант с пулом тратит
всего 40 байт на операцию, а вариант с новыми аллокациями
тратит почти килобайт на операцию. Тысячу байт. За счет того, что мы держим данные в пуле, то есть нам не приходится
каждый раз их аллоцировать, у нас есть какое-то количество
приаллоцированных данных. Если они нам нужны, мы их оттуда берем,
используем и кладем обратно. Это гораздо выгоднее,
чем выделять память каждый раз, чтобы она потом была
убрана сборщиком мусора. Это просто эффективнее. Поэтому если вдруг у вас случаются случаи,
что вам нужно либо аллоцировать очень много структур,
либо же вам нужно аллоцировать много, там, слайс байт, куда вы что-то пишете
и потом сохраняете и выкидываете, то очень хорошим шагом будет
использовать sync.Pool. Он очень здорово экономит память,
и в целом инструмент это полезный. Конечно, sync.Pool — это не панацея. Вы не можете контролировать количество
объектов там, вы не можете контролировать, когда эти объекты действительно
очистятся сборщиком мусора. Да, вы вообще не контролируете там ничего,
кроме функции создания нового объекта. Когда очистить,
уже определяет garbage collector. Но в целом он очень эффективен.