1
00:00:00,000 --> 00:00:05,637
[БЕЗ_ЗВУКА] В

2
00:00:05,637 --> 00:00:12,821
этой серии видео уроков мы рассмотрим
асинхронное программирование и тот подход,

3
00:00:12,821 --> 00:00:16,720
в котором оно реализовано в Go.

4
00:00:16,720 --> 00:00:18,079
Для начала определение.

5
00:00:18,079 --> 00:00:20,740
Что такое вообще асинхронное
программирование?

6
00:00:20,740 --> 00:00:24,578
Асинхронное программирование
— это когда операции

7
00:00:24,578 --> 00:00:29,318
вашей программы выполняются
не строго последовательно,

8
00:00:29,318 --> 00:00:35,440
а могут быть прерваны какими-то
другими операциями вашей же программы.

9
00:00:35,440 --> 00:00:40,594
Самым известным примером асинхронного
программирования является технология

10
00:00:40,594 --> 00:00:45,125
Ajax — асинхронный JavaScript и XML,
когда во время

11
00:00:45,125 --> 00:00:50,500
запроса на сервер ваша
страница не замораживается,

12
00:00:50,500 --> 00:00:53,895
а продолжает работать.

13
00:00:53,895 --> 00:01:00,298
Давайте теперь начнем переходить к тому,

14
00:01:00,298 --> 00:01:06,820
почему вообще асинхронное программирование
появилось и почему оно эффективно.

15
00:01:06,820 --> 00:01:11,869
Прежде чем мы начнем рассматривать то,
каким образом реализована

16
00:01:11,869 --> 00:01:16,179
обработка запроса в
современном веб-сервере,

17
00:01:16,179 --> 00:01:22,760
давайте просмотрим одно понятие в
процессоре, которое важно в этом случае.

18
00:01:22,760 --> 00:01:29,120
Итак, для начала память.

19
00:01:29,120 --> 00:01:34,355
Скорость современного
процессора гораздо больше,

20
00:01:34,355 --> 00:01:37,470
чем скорость оперативной памяти.

21
00:01:37,470 --> 00:01:42,396
Для того чтобы как-то компенсировать это,
был введен кэш процессора,

22
00:01:42,396 --> 00:01:46,110
который располагается вместе
с ним на одном кристалле.

23
00:01:46,110 --> 00:01:49,660
Это очень быстрая память,
но она очень маленькая.

24
00:01:49,660 --> 00:01:53,775
Сначала был введен кэш первого уровня,
потом второго,

25
00:01:53,775 --> 00:01:58,497
потом третьего, когда-нибудь,
скорее всего, введут и четвертого уровня.

26
00:01:58,497 --> 00:02:00,770
После кэша идет уже оперативная память.

27
00:02:00,770 --> 00:02:05,175
То есть вот процессор,
и в нем есть кэш, и он быстрый.

28
00:02:05,175 --> 00:02:09,580
Есть плашки памяти,
которые являются оперативной памятью.

29
00:02:09,580 --> 00:02:11,829
Там память медленнее.

30
00:02:11,829 --> 00:02:17,120
Например, для того чтобы получить
доступ из ядра процессора

31
00:02:17,120 --> 00:02:22,680
в основную оперативную память,
может затребоваться до 100 наносекунд.

32
00:02:22,680 --> 00:02:26,064
С учетом количества операций,
которые выполняет современный процессор,

33
00:02:26,064 --> 00:02:27,110
это достаточно много.

34
00:02:27,110 --> 00:02:31,330
Почему память важна?

35
00:02:31,330 --> 00:02:39,211
Память важна при рассмотрении такого
понятия, как переключение контекста.

36
00:02:39,211 --> 00:02:43,520
Переключение контекста — что это такое?

37
00:02:43,520 --> 00:02:48,241
Процессор выполняет просто последовательно

38
00:02:48,241 --> 00:02:53,050
какие-то операции, он ничего не
знает про какие-то другие программы.

39
00:02:53,050 --> 00:02:58,260
Переключением из одной программы

40
00:02:58,260 --> 00:03:02,880
в другую программу занимается
планировщик задач.

41
00:03:02,880 --> 00:03:05,379
Что он делает?

42
00:03:05,379 --> 00:03:09,230
Он берёт один процесс,

43
00:03:09,230 --> 00:03:13,490
один тред,
сохраняет его состояние куда-то.

44
00:03:13,490 --> 00:03:17,680
Потом берет состояние другого треда,

45
00:03:17,680 --> 00:03:22,890
загружает его в процессор,
и начинается выполняться этот процесс.

46
00:03:22,890 --> 00:03:28,010
Причем здесь память?

47
00:03:28,010 --> 00:03:32,093
Дело в том, что при переключении задач,

48
00:03:32,093 --> 00:03:37,187
переключении процессов или
системных тредов может

49
00:03:37,187 --> 00:03:43,407
возникнуть потребность в обращении
к основной оперативной памяти,

50
00:03:43,407 --> 00:03:47,520
потому что в кэше данных
для этого процесса нет.

51
00:03:47,520 --> 00:03:50,020
И нужно будет их подгрузить,

52
00:03:50,020 --> 00:03:54,720
то есть инвалидировать вообще
весь процессорный кэш.

53
00:03:54,720 --> 00:04:01,952
Поэтому переключение контекста
— операция достаточно дорогая.

54
00:04:01,952 --> 00:04:08,021
Мы можем затратить на нее до одной
микросекунды в современных процессорах,

55
00:04:08,021 --> 00:04:09,680
что довольно много.

56
00:04:09,680 --> 00:04:13,886
Именно из-за переключения контекста,

57
00:04:13,886 --> 00:04:17,901
когда вы увеличиваете количество программ,

58
00:04:17,901 --> 00:04:24,940
которые выполняются на вашем компьютере,
всё начинает работать медленнее.

59
00:04:24,940 --> 00:04:29,287
Этот подход к вытеснению
одной программы другой,

60
00:04:29,287 --> 00:04:34,501
это называется вытесняющей
многозадачностью.

61
00:04:34,501 --> 00:04:38,744
Теперь, помня и зная про
переключение контекста,

62
00:04:38,744 --> 00:04:45,440
можно начать рассматривать уже методы
обработки запросов в веб-сервере.

63
00:04:45,440 --> 00:04:52,502
Итак, начнем мы с технологии cgi-bin.

64
00:04:52,502 --> 00:04:53,700
Что это такое?

65
00:04:53,700 --> 00:04:58,763
cgi-bin — это когда на каждый запрос

66
00:04:58,763 --> 00:05:03,447
поднимается новая программа,
создается новый процесс,

67
00:05:03,447 --> 00:05:07,040
это тяжелая операция, это нужно
подключить довольно много памяти.

68
00:05:07,040 --> 00:05:12,086
Там выполняется какой-то запрос,

69
00:05:12,086 --> 00:05:17,873
и после этого программа убивается.

70
00:05:17,873 --> 00:05:22,166
Это может быть очень не эффективно,

71
00:05:22,166 --> 00:05:26,496
потому что при увеличении
количества запросов мы

72
00:05:26,496 --> 00:05:31,235
начнем тратить много времени
на создание и завершение

73
00:05:31,235 --> 00:05:35,610
процессов и можем банально упереться
в количество оперативной памяти.

74
00:05:35,610 --> 00:05:40,467
Эволюцией этого подхода
является worker pool,

75
00:05:40,467 --> 00:05:45,342
когда у нас есть некое количество
процессов, которые не убиваются после

76
00:05:45,342 --> 00:05:50,810
завершения работы,
а остаются в ожидании следующего запроса.

77
00:05:50,810 --> 00:05:56,340
Также есть подход,
который называется мультитрединг.

78
00:05:56,340 --> 00:06:01,488
Это значит, что мы уже создаем не

79
00:06:01,488 --> 00:06:08,367
целый процесс на один запрос или
одно соединение, а всего лишь тред.

80
00:06:08,367 --> 00:06:13,623
Тред — это более легкая сущность,
чем процесс.

81
00:06:13,623 --> 00:06:17,552
Тред имеет доступ к памяти
своего процесса, То есть

82
00:06:17,552 --> 00:06:21,310
вы можете переиспользовать какие-то
соединения, например, к базе данных.

83
00:06:21,310 --> 00:06:24,630
Тред занимает меньше памяти,

84
00:06:24,630 --> 00:06:30,031
но для процессора это тоже системный тред,

85
00:06:30,031 --> 00:06:33,780
он тоже выполняется процессором,
его тоже нужно переключать context switch.

86
00:06:33,780 --> 00:06:39,147
Таким образом,
за счет хотя бы экономии памяти

87
00:06:39,147 --> 00:06:43,709
мы можем обработать большее
количество запросов.

88
00:06:43,709 --> 00:06:46,544
Также эволюцией тут является то,

89
00:06:46,544 --> 00:06:51,230
что мы можем создать worker
pool и обрабатывать запросы,

90
00:06:51,230 --> 00:06:55,420
не плодя бесконечно новые треды,

91
00:06:55,420 --> 00:06:59,880
а распределять запросы по
фиксированному количеству.

92
00:06:59,880 --> 00:07:03,933
Может быть, это как-то можно ускорить?

93
00:07:03,933 --> 00:07:08,790
Для того чтобы понять это,
давайте посмотрим внутрь запроса,

94
00:07:08,790 --> 00:07:13,150
что происходит внутри запроса сейчас.

95
00:07:13,150 --> 00:07:18,223
На самом деле оновное время на
современном web api уходит на

96
00:07:18,223 --> 00:07:24,080
ожидание запроса от какой-то удаленной
базы данных, от какого-то веб-сервиса.

97
00:07:24,080 --> 00:07:29,470
И в случае с подходом

98
00:07:29,470 --> 00:07:35,070
с процессами на запрос либо тредом
на запрос получается так, что тред

99
00:07:35,070 --> 00:07:41,420
блокируется на ожидание этого ответа и не
выполняет никакой другой полезной работы.

100
00:07:41,420 --> 00:07:46,135
Из понимания этого

101
00:07:46,135 --> 00:07:52,420
родился событийный подход
к обработке запросов,

102
00:07:52,420 --> 00:07:58,280
который реализован, например,
в JS, в JavaScript.

103
00:07:58,280 --> 00:08:00,730
Что это значит?

104
00:08:00,730 --> 00:08:07,207
Это значит,
что у нас неблокирующий ввод-вывод.

105
00:08:07,207 --> 00:08:11,272
Когда мы отправили запрос в базу данных,

106
00:08:11,272 --> 00:08:16,720
мы на этом не блокируемся,
мы продолжаем выполнять какие-то

107
00:08:16,720 --> 00:08:21,620
другие запросы,
потому что процессор у нас бездействует.

108
00:08:21,620 --> 00:08:26,810
Таким образом, мы можем получить
очень хорошую производительность.

109
00:08:26,810 --> 00:08:33,570
Мы можем обрабатывать много
запросов внутри одного треда.

110
00:08:33,570 --> 00:08:35,977
Но тут есть нюансы.

111
00:08:35,977 --> 00:08:37,820
Какие нюансы?

112
00:08:37,820 --> 00:08:43,250
Дело в том, что,
поскольку у нас тред один,

113
00:08:43,250 --> 00:08:47,340
то мы никак не можем выполнять
параллельно запросы.

114
00:08:47,340 --> 00:08:50,550
В случае с вытесняющей многозадачностью,

115
00:08:50,550 --> 00:08:55,025
когда тред блокируется,
какой-то другой тред работает.

116
00:08:55,025 --> 00:09:00,006
В случае с кооперативной многозадачностью
в этом случае, то мы должны

117
00:09:00,006 --> 00:09:04,879
дождаться окончания работы
запроса № 1 для того,

118
00:09:04,879 --> 00:09:11,410
чтобы выполнять запрос № 2, и

119
00:09:11,410 --> 00:09:17,228
это может быть плохо,

120
00:09:17,228 --> 00:09:21,194
если у нас много операций на ЦПУ.

121
00:09:21,194 --> 00:09:25,772
Например, мы считаем какие-то хеши,
занимаемся шифрованием либо

122
00:09:25,772 --> 00:09:30,674
архивированием, потому что это тяжелая
процессорная операция, и нам будет не

123
00:09:30,674 --> 00:09:35,400
хватать того времени, которое мы проводим
в ожидании ответов от базы данных.

124
00:09:35,400 --> 00:09:40,330
Нам будет не хватать для обработки
всех операций, всех запросов.

125
00:09:40,330 --> 00:09:46,675
Соответственно, хочется как-то
разнести это на несколько ядер,

126
00:09:46,675 --> 00:09:52,810
для того чтобы, пока один тред занят,
мы могли выполнять что-то в другом треде.

127
00:09:52,810 --> 00:09:55,734
То есть размасштабироваться.

128
00:09:55,734 --> 00:09:59,308
И именно такой подход реализован в Go.

129
00:09:59,308 --> 00:10:04,210
Основан он на модели, которая называется
communicating sequential processes

130
00:10:04,210 --> 00:10:09,250
от Тони Хоара,
и оперируем мы в этом подходе

131
00:10:09,250 --> 00:10:14,540
такой сущностью, как горутина.

132
00:10:14,540 --> 00:10:20,003
Горутина — это аналог сопрограммы,
когда в одном системном

133
00:10:20,003 --> 00:10:25,068
треде может выполняться несколько горутин,
несколько сопрограмм.

134
00:10:25,068 --> 00:10:27,610
При этом особенностью является то,

135
00:10:27,610 --> 00:10:32,555
что наша горутина может начать
выполняться на одном треде,

136
00:10:32,555 --> 00:10:38,285
потом уйти в ожидание данных из базы и
продолжить выполняться в другом системном

137
00:10:38,285 --> 00:10:43,540
треде, потому что первый системный тред
занят уже какой-то другой горутиной.

138
00:10:43,540 --> 00:10:46,990
Этот подход позволяет получить
очень хорошую производительность,

139
00:10:46,990 --> 00:10:49,040
очень хорошую пропускную способность.

140
00:10:49,040 --> 00:10:54,367
Это является одним из
ключевых особенностей языка

141
00:10:54,367 --> 00:10:59,300
Go и одной из самых сильных его сторон.

142
00:10:59,300 --> 00:11:05,410
А теперь давайте рассмотрим,
как это выглядит в коде.